#
# Apache v2 license
# Copyright (C) 2023 Intel Corporation
# SPDX-License-Identifier: Apache-2.0
#

- fail:
    msg: "The native module only supports a single SUT."
  when: groups.workload_hosts | length > 1

- name: check sudo permission
  fail:
    msg: "sudo is required for --native execution on the SUT."
  when: not (sut_sudo | default(true) | bool)

- set_fact:
    docker_config1: "{{ docker_config[inventory_hostname] }}"
  vars:
    docker_config: "{% if (wl_logs_dir+'/docker-config.yaml') is exists %}{{ lookup('file',wl_logs_dir+'/docker-config.yaml') | from_yaml }}{% else %}{{ {'worker-0':[{'image':workload_config.docker_image,'options':workload_config.docker_options,'export-logs':true}]} }}{% endif %}"

- name: test if single container
  fail:
    msg: "multiple container workloads on the same SUT is not supported"
  when: docker_config1 | length != 1
        
- name: set workspace
  set_fact:
    workspace: "/tmp/{{ wl_namespace }}-workspace"

- name: get proxy strings
  shell: 
    cmd: |
      for k in $(compgen -e | grep -iE '_proxy$'); do
        eval 'v=$'$k
        echo "export $k=$v"
      done
    executable: /bin/bash
  register: proxies

- name: get data disks
  find:
    path: "{{ item.path }}"
    patterns: '{{ item.patterns }}'
    file_type: directory
    recurse: false
  register: disks
  loop:
  - path: /mnt
    patterns: 'disk?'
  - path: /opt/dataset
    patterns: '*'

- name: save the disks to be cleanup
  copy:
    content: "{{ disks | to_yaml }}"
    dest: "{{ wl_logs_dir }}/tocleanup.yaml"
  delegate_to: localhost

- name: Create remote workspace
  block:

    - name: create the remote workspace
      file:
        path: "{{ workspace }}"
        state: directory

    - name: invoke docker create
      shell:
        cmd: "docker create {% for r in sut_accessible_registries | default(skopeo_sut_accessible_registries|default(''),true) | split(',') | reject('==','') %}{% if item.image.startswith(r) %}--pull always {% endif %}{% endfor %} --platform={{ workload_config.image_arch }} {% if (((ansible_connection|default('ssh')) in ['local']) or (ansible_host in (my_ip_list|split(',')))) and ('/' in workload_config.registry) %}--pull always{% endif %} --platform={{ workload_config.image_arch }} {% if (docker_config1[0].options|type_debug)=='list' %}{{ docker_config1[0].options|map('string')|join(' ') }}{% else %}{{ docker_config1[0].options|default('',true)|string }}{% endif %} {% if (docker_config1[0].options|type_debug)=='list' %}{% if docker_config1[0].image not in (docker_config1[0].options|map('string')) %}{{ docker_config1[0].image }}{% endif %}{% else %}{% if docker_config1[0].image not in (docker_config1[0].options|default('',true)|split(' ')) %}{{ docker_config1[0].image }}{% endif %}{% endif %} {% if docker_config1[0].command is defined %} {{ docker_config1[0].command }} {% endif %}"
        executable: /bin/bash
      register: container_id
      delegate_to: localhost
      become: true

    - name: inspect docker container
      command: "docker container inspect {{ container_id.stdout }} -f '{{ '{{' }}json .}}'"
      register: container_info
      delegate_to: localhost
      become: true
      no_log: true

    - include_role:
        name: timing
        tasks_from: start-image-transfer

    - name: copy the workload file system
      shell:
        cmd: |
          sudo -E -H docker container export {{ container_id.stdout }} | gzip | ssh {% if ansible_private_key_file is defined %}-i {{ ansible_private_key_file }}{% endif %} -p {{ ansible_port | default(22) }} {{ ansible_user }}@{{ ansible_host }} sudo tar xfz - -p -C {{ workspace }}
        executable: /bin/bash
      delegate_to: localhost

    - include_role:
        name: timing
        tasks_from: stop-image-transfer

  always:

    - name: remove container
      command: "docker rm -v -f {{ container_id.stdout }}"
      delegate_to: localhost
      become: true
      ignore_errors: true
      when: ((itr |int) < (run_stage_iterations | default(1) | int)) or ('cleanup' not in (stage | default('cleanup')))

- name: set container info (1)
  set_fact:
    container_info: "{{ container_info.stdout | from_json }}"

- name: workload execution procedure
  block:

    - name: mount /proc, /sys, /dev, /etc/localtime
      shell: |
        mount -t proc /proc {{ workspace }}/proc
        mount --rbind /sys {{ workspace }}/sys
        mount --make-rslave {{ workspace }}/sys
        mount --rbind /dev {{ workspace }}/dev
        mount --make-rslave {{ workspace }}/dev
        if [ ! -d {{ workspace }}/usr/share/zoneinfo ]; then
          touch {{ workspace }}/etc/localtime
          mount --bind /etc/localtime {{ workspace }}/etc/localtime
        fi
      become: true

    - name: mount disks
      shell: |
        mkdir -p {{ workspace }}{{ item.path }}
        mount --bind {{ item.path }} {{ workspace }}{{ item.path }}
      loop: "{{ disks | json_query('results[*].files') | flatten }}"
      become: true

    - include_role:
        name: timing
        tasks_from: start-iteration

    - name: create startup script
      copy:
        content: |
          export TZ=$1
          shift
          [ -d /usr/share/zoneinfo ] && ln -sf /usr/share/zoneinfo/$TZ /etc/localtime
          cd {{ container_info.Config.WorkingDir | default('/',true) }}
          {% for env1 in container_info.Config.Env %}
            export '{{ env1 }}'
          {% endfor %}
          {% for k in workload_secrets.keys() %}
            export {{ k }}='{{ workload_secrets[k] }}'
          {% endfor %}
          {{ proxies.stdout }}
          {% if docker_config1[0].image in (docker_options|split(' ')) %}
            {% for cmd1 in (container_info.Config.Entrypoint|default(['/bin/sh','-c'],true)) %}'{{ cmd1 | replace(sq,sq+dq+sq+dq+sq) }}' {% endfor %} {{ docker_options.split(' '+docker_config1[0].image+' ')[-1] }} {{ docker_config1[0].command | default('') }}
          {% else %}
            {% for cmd1 in container_info.Config.Cmd %}'{{ cmd1 | replace(sq,sq+dq+sq+dq+sq) | replace('-c', '-vxc') }}' {% endfor %} {{ docker_config1[0].command | default('') }}
          {% endif %}
        mode: 700
        dest: "{{ workspace }}/tmp/{{ wl_namespace }}-startup"
      become: true
      environment: "{{ workload_secrets }}"
      vars:
        workload_secrets: "{% if (wl_logs_dir+'/.workload-secret.yaml') is exists %}{{ lookup('file',wl_logs_dir+'/.workload-secret.yaml') | from_yaml | default({},true) }}{% else %}{{ {} }}{% endif %}"
        sq: "'"
        dq: '"'
        nl: "\n"
        docker_options: "{% if (docker_config1[0].options|type_debug)=='list' %}{{ docker_config1[0].options|map('string')|join(' ') }}{% else %}{{ docker_config1[0].options|default('',true)|string }}{% endif %}"

    - name: run the workload natively
      shell:
        executable: /bin/bash
        cmd: |
          nohup timeout {{ workload_config.timeout | split(',') | first }}s chroot --userspec={{ container_info.Config.User | default('root',true) }} {{ workspace }} /bin/sh /tmp/{{ wl_namespace }}-startup $(timedatectl show --va -p Timezone 2> /dev/null || echo $TZ) > /tmp/{{ wl_namespace }}-logs 2>&1 & 
          echo $!
          disown
      register: pid
      become: true

    - name: waitproc to wait for logs complete
      shell:
        cmd: |
          nohup bash -c 'timeout {{ workload_config.timeout | split(',') | first }}s cat {{ workspace }}{{ workload_config.export_logs }} > /tmp/{{ wl_namespace }}-logs.tar;echo $? > /tmp/{{ wl_namespace }}-{{ inventory_hostname }}-waitproc.status; tar tf /tmp/{{ wl_namespace }}-logs.tar || tar cf /tmp/{{ wl_namespace }}-logs.tar -C {{ workspace }} $(cat /tmp/{{ wl_namespace }}-logs.tar | tr " " "\n")' > /dev/null 2>&1 &
          echo $!
          disown
        executable: /bin/bash
      register: waitproc

    - name: invoke the trace procedure
      include_role:
        name: trace
      vars:
        trace_waitproc_pid: "{{ waitproc.stdout }}"
        trace_logs_scripts: ["cat /tmp/{{ wl_namespace }}-logs"]
        trace_status_file: "/tmp/{{ wl_namespace }}-{{ inventory_hostname }}-waitproc.status"

  always:

    - include_role:
        name: timing
        tasks_from: stop-iteration

    - name: kill the worker process
      command: "kill {{ pid.stdout }}"
      become: true
      ignore_errors: true

- name: collect trace data
  include_role:
    name: trace
    tasks_from: collect
  when: wl_trace_modules | default('') | split(',') | reject('==','') | length > 0

- name: print logs
  command: "cat /tmp/{{ wl_namespace }}-logs"
  ignore_errors: true

- name: create the iteration direcctory
  file:
    path: "{{ wl_logs_dir }}/itr-{{ itr }}/worker-0"
    state: directory
  delegate_to: localhost

- block:

  - name: copy logs back to the itr directory
    fetch:
      src: "/tmp/{{ wl_namespace }}-logs.tar"
      dest: "{{ wl_logs_dir }}/itr-{{ itr }}/"
      flat: yes

  - name: untar the logs
    unarchive:
      src: "{{ wl_logs_dir }}/itr-{{ itr }}/{{ wl_namespace }}-logs.tar"
      dest: "{{ wl_logs_dir}}/itr-{{ itr }}/worker-0"
    delegate_to: localhost

  always:

  - name: remove local logs tarfile
    file:
      path: "{{ wl_logs_dir }}/itr-{{ itr }}/{{ wl_namespace }}-logs.tar"
      state: absent
    delegate_to: localhost
    ignore_errors: true 

  ignore_errors: true

- name: append build_commit_id and build_branch to workload-config.yaml
  blockinfile:
    path: "{{ wl_logs_dir }}/workload-config.yaml"
    marker: "# {mark} BUILD CONFIG"
    content: |
      build_commit_id: "{{ image_labels | selectattr('key', '==', 'BUILD_COMMIT_ID') | map(attribute='value') | unique | join(',') }}"
      build_branch: "{{ image_labels | selectattr('key', '==', 'BUILD_BRANCH') | map(attribute='value') | unique | join(',') }}"
  delegate_to: localhost
  become: false
  vars:
    image_labels: "{{ 'Labels' | extract('Config' | extract(container_info) | default([],true)) | default({},true) | dict2items }}"
  ignore_errors: true

- name: cleanup workspace
  include_role:
    name: cleanup
    tasks_from: cleanup-native
  when: ((itr |int) < (run_stage_iterations | default(1) | int)) or ('cleanup' not in (stage | default('cleanup')))

